{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise,first I'll use the functions I defined in previous exercises, namely, bin_spatial(), color_hist(), and extract_features() then read in my car and non-car images and extract the color features for each. All that remains is to define a labels vector, shuffle and split the data into training and testing sets, scale the feature vectors to zero mean and unit variance, and finally, define a classifier and train it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My labels vector **y** in this case will just be a binary vector indicating whether each feature vector in our dataset corresponds to a car or non-car (1's for cars, 0's for non-cars). Given lists of car and non-car features (the output of extract_features()) I can define a labels vector like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~python\n",
    "import numpy as np\n",
    "# Define a labels vector based on features lists\n",
    "y = np.hstack((np.ones(len(car_features)), \n",
    "              np.zeros(len(notcar_features))))\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll stack my feature vectors like before:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~python\n",
    "# Create an array stack of feature vectors\n",
    "X = np.vstack((car_features, notcar_features)).astype(np.float64)\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now I am ready to shuffle and split the data into training and testing sets. To do this I'll use the Scikit-Learn train_test_split() function, but it's worth noting that recently, this function moved from the sklearn.cross_validation package (in sklearn version <=0.17) to the sklearn.model_selection package (in sklearn version >=0.18)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~python\n",
    "from sklearn.cross_validation import train_test_split\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_test_split() performs both the shuffle and split of the data and I'll call it like this (here choosing to initialize the shuffle with a different random state each time):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~python\n",
    "# Split up data into randomized training and test sets\n",
    "rand_state = np.random.randint(0, 100)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=rand_state)\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have split into training and test sets, I can scale my features. It's important to do the scaling after splitting the data, otherwise I are allowing the scaler to peer into your test data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~python\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Fit a per-column scaler only on the training data\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "# Apply the scaler to both X_train and X_test\n",
    "scaled_X_train = X_scaler.transform(X_train)\n",
    "scaled_X_test = X_scaler.transform(X_test)\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning: when dealing with image data that was extracted from video, you may be dealing with sequences of images where your target object (vehicles in this case) appear almost identical in a whole series of images. In such a case, even a randomized train-test split will be subject to overfitting because images in the training set may be nearly identical to images in the test set. For the subset of images used in the next several quizzes, this is not a problem, but to optimize your classifier for the project, you may need to worry about time-series of images!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I am ready to define and train a classifier! Here I will try a Linear Support Vector Machine. To define and train my classifier it takes just a few lines of code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~python\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "# Use a linear SVC (support vector classifier)\n",
    "svc = LinearSVC()\n",
    "# Train the SVC\n",
    "svc.fit(scaled_X_train, y_train)\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I can check the accuracy of your classifier on the test dataset like this: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~python\n",
    "print('Test Accuracy of SVC = ', svc.score(scaled_X_test, y_test))\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or I can make predictions on a subset of the test data and compare directly with ground truth:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~python\n",
    "print('My SVC predicts: ', svc.predict(scaled_X_test[0:10].reshape(1, -1)))\n",
    "print('For labels: ', y_test[0:10])\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the exercise below to see how the classifier accuracy and training time vary with the feature vector input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_spatial(img,size=(32,32)):\n",
    "    features=cv2.resize(img,size).ravel()\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_hist(img,nbins=32,bins_range=(0,256)):\n",
    "    \n",
    "    channel1_hist=np.histogram(img[:,:,0],bins=nbins,range=bins_range)\n",
    "    channel2_hist=np.histogram(img[:,:,1],bins=nbins,range=bins_range)\n",
    "    channel3_hist=np.histogram(img[:,:,2],bins=nbins,range=bins_range)\n",
    "    \n",
    "    hist_features=np.concatenate((channel1_hist[0],channel2_hist[0],channel3_hist[0]))\n",
    "    return hist_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(CarDirectory,NonCarDirectory):\n",
    "    CarImages=[]\n",
    "    NonCarImages=[]\n",
    "    CarImages=glob.glob(CarDirectory,recursive=True)\n",
    "    NonCarImages=glob.glob(NonCarDirectory,recursive=True)\n",
    "    \n",
    "    data_dict={}\n",
    "    \n",
    "    data_dict['CarImages']=CarImages\n",
    "    data_dict['NonCarImages']=NonCarImages\n",
    "    \n",
    "    # Define a key in data_dict \"n_cars\" and store the number of car images\n",
    "    data_dict[\"n_cars\"] = len(CarImages)\n",
    "    # Define a key \"n_notcars\" and store the number of notcar images\n",
    "    data_dict[\"n_notcars\"] = len(NonCarImages)\n",
    "    # Read in a test image, either car or notcar\n",
    "    example_img = mpimg.imread(CarImages[0])\n",
    "    # Define a key \"image_shape\" and store the test image shape 3-tuple\n",
    "    data_dict[\"image_shape\"] = example_img.shape\n",
    "    # Define a key \"data_type\" and store the data type of the test image.\n",
    "    data_dict[\"data_type\"] = example_img.dtype\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(imgs, cspace='RGB', spatial_size=(32, 32),\n",
    "                        hist_bins=32, hist_range=(0, 256)):\n",
    "    # Create a list to append feature vectors to\n",
    "    features = []\n",
    "    # Iterate through the list of images\n",
    "    for file in imgs:\n",
    "        # Read in each one by one\n",
    "        image = mpimg.imread(file)\n",
    "        # apply color conversion if other than 'RGB'\n",
    "        if cspace != 'RGB':\n",
    "            if cspace == 'HSV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "            elif cspace == 'LUV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2LUV)\n",
    "            elif cspace == 'HLS':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "            elif cspace == 'YUV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n",
    "        else: feature_image = np.copy(image)      \n",
    "        # Apply bin_spatial() to get spatial color features\n",
    "        spatial_features = bin_spatial(feature_image, size=spatial_size)\n",
    "        # Apply color_hist() also with a color space option now\n",
    "        hist_features = color_hist(feature_image, nbins=hist_bins, bins_range=hist_range)\n",
    "        # Append the new feature vector to the features list\n",
    "        features.append(np.concatenate((spatial_features, hist_features)))\n",
    "    # Return list of feature vectors\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "CarDirectory='../dataset/vehicles_smallset/*/*.jpeg'\n",
    "NonCarDirectory='../dataset/non-vehicles_smallset/*/*.jpeg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict=get_dataset(CarDirectory,NonCarDirectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your function returned a count of 1196  cars and 1125  non-cars\n",
      "of size:  (64, 64, 3)  and data type: uint8\n"
     ]
    }
   ],
   "source": [
    "print('Your function returned a count of', \n",
    "      data_dict[\"n_cars\"], ' cars and', \n",
    "      data_dict[\"n_notcars\"], ' non-cars')\n",
    "\n",
    "print('of size: ',data_dict[\"image_shape\"], ' and data type:', \n",
    "      data_dict[\"data_type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_features = extract_features(data_dict['CarImages'], cspace='RGB',\n",
    "                                spatial_size=(32, 32),hist_bins=32, hist_range=(0, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "notcar_features = extract_features(data_dict['NonCarImages'], cspace='RGB',\n",
    "                                   spatial_size=(32, 32),hist_bins=32, hist_range=(0, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1125 (3168,)\n",
      "1196 (3168,)\n"
     ]
    }
   ],
   "source": [
    "print(len(notcar_features),notcar_features[0].shape)\n",
    "print(len(car_features),car_features[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2321, 3168)\n"
     ]
    }
   ],
   "source": [
    "X = np.vstack((car_features, notcar_features)).astype(np.float64)                        \n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2321,)\n"
     ]
    }
   ],
   "source": [
    "# Create an array stack of feature vectors\n",
    "y=np.hstack((np.ones(len(car_features)),np.zeros(len(notcar_features))))\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split up data into randomized training and test sets\n",
    "rand_sate=np.random.randint(0,100)\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=rand_sate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1856, 3168) (1856,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(465, 3168) (465,)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a per-column scaler only on the training data\n",
    "X_scaler=StandardScaler().fit(X_train)\n",
    "# Apply the scaler to X_train and X_test\n",
    "\n",
    "X_train=X_scaler.transform(X_train)\n",
    "X_test=X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.38 Second to train SVC ...\n"
     ]
    }
   ],
   "source": [
    "# Use a linear SVC \n",
    "svc = LinearSVC()\n",
    "# Check the training time for the SVC\n",
    "t=time.time()\n",
    "svc.fit(X_train,y_train)\n",
    "print(round(time.time()-t,2),'Second to train SVC ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test the accuracy of the SVC=  1.0\n"
     ]
    }
   ],
   "source": [
    "# Check the score of the SVC\n",
    "print('Test the accuracy of the SVC= ', round(svc.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my SVC predicts:  [0. 0. 1. 0. 1. 1. 0. 1. 1. 0.]\n",
      "for these  10 labels:  [1. 0. 1. 0. 1. 1. 0. 1. 1. 0.]\n",
      "0.0 Second to train SVC ...\n"
     ]
    }
   ],
   "source": [
    "# Check the prediction time for a single sample\n",
    "t=time.time()\n",
    "n_predicts=10\n",
    "print('my SVC predicts: ',svc.predict(X_test[0:n_predicts]))\n",
    "print('for these ', n_predicts, 'labels: ',y_test[0:n_predicts])\n",
    "print(round(time.time()-t,2),'Second to train SVC ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
