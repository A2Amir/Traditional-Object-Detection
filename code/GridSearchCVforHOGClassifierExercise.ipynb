{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In the exercise below, first i am going to tune the HOG Classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation with GridSearchCV\n",
    "\n",
    "GridSearchCV uses 3-fold cross validation to determine the best performing parameter set. GridSearchCV will take in a training set and divide the training set into three equal partitions. The algorithm will train on two partitions and then validate using the third partition. Then GridSearchCV chooses a different partition for validation and trains with the other two partitions. Finally, GridSearchCV uses the last remaining partition for cross-validation and trains with the other two partitions.\n",
    "\n",
    "By default, GridSearchCV uses accuracy as an error metric by averaging the accuracy for each partition. So for every possible parameter combination, GridSearchCV calculates an accuracy score. Then GridSearchCV will choose the parameter combination that performed the best.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit-learn Cross Validation Example\n",
    "\n",
    "Here's an example from the sklearn [documentation](http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.GridSearchCV.html) for implementing GridSearchCV:\n",
    "\n",
    "~~~python\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn import svm\n",
    "    parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
    "    svr = svm.SVC()\n",
    "    clf = grid_search.GridSearchCV(svr, parameters)\n",
    "    clf.fit(iris.data, iris.target)\n",
    "~~~\n",
    "Let's break this down line by line.\n",
    "\n",
    "    parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
    "\n",
    "A dictionary of the parameters, and the possible values they may take. In this case, they're playing around with the kernel (possible choices are 'linear' and 'rbf'), and C (possible choices are 1 and 10).\n",
    "\n",
    "Then a 'grid' of all the following combinations of values for (kernel, C) are automatically generated:\n",
    "\n",
    "    ('rbf', 1) \t('rbf', 10)\n",
    "    ('linear', 1) \t('linear', 10)\n",
    "\n",
    "Each is used to train an SVM, and the performance is then assessed using cross-validation.\n",
    "\n",
    "    svr = svm.SVC()\n",
    "    \n",
    "This looks kind of like creating a classifier, But note that the \"clf\" isn't made until the next line--this is just saying what kind of algorithm to use. Another way to think about this is that the \"classifier\" isn't just the algorithm in this case, it's algorithm plus parameter values. Note that there's no monkeying around with the kernel or C; all that is handled in the next line.\n",
    "\n",
    "    clf = grid_search.GridSearchCV(svr, parameters)\n",
    "    \n",
    "This is where the first bit of magic happens; the classifier is being created. I pass the algorithm (svr) and the dictionary of parameters to try (parameters) and it generates a grid of parameter combinations to try.\n",
    "\n",
    "    clf.fit(iris.data, iris.target)\n",
    "    \n",
    "And the second bit of magic. The fit function now tries all the parameter combinations, and returns a fitted classifier that's automatically tuned to the optimal parameter combination. I can now access the parameter values via \n",
    "    \n",
    "    clf.best_params_.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from skimage.feature import hog\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hog_features(img,orient,pix_per_cell,cell_per_block,vis=False,feature_vec=True):\n",
    "        \n",
    "        if vis==True:\n",
    "            features,hog_image=hog(img,orientations=orient,\n",
    "                                     pixels_per_cell=(pix_per_cell,pix_per_cell),\n",
    "                                     cells_per_block=(cell_per_block,cell_per_block),\n",
    "                                     block_norm=\"L2-Hys\",\n",
    "                                     transform_sqrt=True,\n",
    "                                     visualise=vis,\n",
    "                                     feature_vector=feature_vec)\n",
    "            return features,hog_image\n",
    "        else:\n",
    "            features=hog(img,orientations=orient,\n",
    "                                     pixels_per_cell=(pix_per_cell,pix_per_cell),\n",
    "                                     cells_per_block=(cell_per_block,cell_per_block),\n",
    "                                     block_norm=\"L2-Hys\",\n",
    "                                     transform_sqrt=True,\n",
    "                                     visualise=vis,\n",
    "                                     feature_vector=feature_vec)\n",
    "            return features\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(imgs,cspace='RGB',orient=9,pix_per_cell=8,cell_per_block=2,hog_channel=0):\n",
    "    features=[]\n",
    "    for file in imgs:\n",
    "        image=mpimg.imread(file)\n",
    "        if cspace!='RGB':\n",
    "            if cspace=='HSV':\n",
    "                feature_image=cv2.cvtColor(image,cv2.COLOR_RGB2HSV)\n",
    "            if cspace=='LUV':\n",
    "                feature_image=cv2.cvtColor(image,cv2.COLOR_RGB2LUV)\n",
    "            if cspace=='HLS':\n",
    "                feature_image=cv2.cvtColor(image,cv2.COLOR_RGB2HLS)                \n",
    "            if cspace=='YUV':\n",
    "                feature_image=cv2.cvtColor(image,cv2.COLOR_RGB2YUV) \n",
    "            if cspace=='YCrCb':\n",
    "                feature_image=cv2.cvtColor(image,cv2.COLOR_RGB2YCrCb)\n",
    "        else:\n",
    "            feature_image=np.copy(image)\n",
    "        \n",
    "        \n",
    "        if hog_channel==\"ALL\":\n",
    "            hog_features= []\n",
    "            for channel in range(feature_image.shape[2]):\n",
    "                hog_features.append(get_hog_features(feature_image[:,:,channel],\n",
    "                                                    orient,pix_per_cell,cell_per_block,\n",
    "                                                    vis=False,feature_vec=True))\n",
    "            hog_features=np.ravel(hog_features)\n",
    "        else:\n",
    "            hog_features=get_hog_features(feature_image[:,:,hog_channel],\n",
    "                                                    orient,pix_per_cell,cell_per_block,\n",
    "                                                    vis=False,feature_vec=True)\n",
    "        features.append(hog_features)\n",
    "        \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(CarDirectory,NonCarDirectory):\n",
    "    CarImages=[]\n",
    "    NonCarImages=[]\n",
    "    CarImages=glob.glob(CarDirectory,recursive=True)\n",
    "    NonCarImages=glob.glob(NonCarDirectory,recursive=True)\n",
    "    \n",
    "    data_dict={}\n",
    "    \n",
    "    data_dict['CarImages']=CarImages\n",
    "    data_dict['NonCarImages']=NonCarImages\n",
    "    \n",
    "    # Define a key in data_dict \"n_cars\" and store the number of car images\n",
    "    data_dict[\"n_cars\"] = len(CarImages)\n",
    "    # Define a key \"n_notcars\" and store the number of notcar images\n",
    "    data_dict[\"n_notcars\"] = len(NonCarImages)\n",
    "    # Read in a test image, either car or notcar\n",
    "    example_img = mpimg.imread(CarImages[0])\n",
    "    # Define a key \"image_shape\" and store the test image shape 3-tuple\n",
    "    data_dict[\"image_shape\"] = example_img.shape\n",
    "    # Define a key \"data_type\" and store the data type of the test image.\n",
    "    data_dict[\"data_type\"] = example_img.dtype\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "CarDirectory='../dataset/vehicles_smallset/*/*.jpeg'\n",
    "NonCarDirectory='../dataset/non-vehicles_smallset/*/*.jpeg'\n",
    "data_dict=get_dataset(CarDirectory,NonCarDirectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your function returned a count of 1196  cars and 1125  non-cars\n",
      "of size:  (64, 64, 3)  and data type: uint8\n"
     ]
    }
   ],
   "source": [
    "print('Your function returned a count of', \n",
    "      data_dict[\"n_cars\"], ' cars and', \n",
    "      data_dict[\"n_notcars\"], ' non-cars')\n",
    "\n",
    "print('of size: ',data_dict[\"image_shape\"], ' and data type:', \n",
    "      data_dict[\"data_type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "colorspace = 'HLS' # Can be RGB, HSV, LUV, HLS, YUV, YCrCb\n",
    "orient = 9\n",
    "pix_per_cell = 8\n",
    "cell_per_block = 2\n",
    "hog_channel = \"ALL\" # Can be 0, 1, 2, or \"ALL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.38 Seconds to extract HOG features...\n"
     ]
    }
   ],
   "source": [
    "t=time.time()\n",
    "car_features=extract_features(data_dict['CarImages'],cspace=colorspace,\n",
    "                              orient=orient,pix_per_cell=pix_per_cell,\n",
    "                             cell_per_block=cell_per_block,\n",
    "                             hog_channel=hog_channel)\n",
    "print(round(time.time()-t, 2), 'Seconds to extract HOG features...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.94 Seconds to extract HOG features...\n"
     ]
    }
   ],
   "source": [
    "t=time.time()\n",
    "Noncar_features=extract_features(data_dict['NonCarImages'],cspace=colorspace,\n",
    "                              orient=orient,pix_per_cell=pix_per_cell,\n",
    "                             cell_per_block=cell_per_block,\n",
    "                             hog_channel=hog_channel)\n",
    "print(round(time.time()-t, 2), 'Seconds to extract HOG features...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an array stack of feature vectors\n",
    "X=np.vstack((car_features,Noncar_features)).astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the labels vector\n",
    "y=np.hstack((np.ones(len(car_features)),np.zeros(len(Noncar_features))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2321, 5292)\n",
      "(2321,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_state=np.random.randint(0,100)\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=rand_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler=StandardScaler().fit(X_train)\n",
    "X_train=X_scaler.transform(X_train)\n",
    "X_test=X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.11 Second to to find SVC parmaeters..\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t=time.time()\n",
    "svc=svm.SVC()\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
    "clf = GridSearchCV(svc, parameters)\n",
    "clf.fit(X_train,y_train)\n",
    "print(round(time.time()-t,2),'Second to to find SVC parmaeters..')\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.07 Second to train SVC..\n"
     ]
    }
   ],
   "source": [
    "t=time.time()\n",
    "svc=svm.SVC(C=10.0, kernel='rbf')\n",
    "svc.fit(X_train,y_train)\n",
    "print(round(time.time()-t,2),'Second to train SVC..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of SVC 0.97849\n"
     ]
    }
   ],
   "source": [
    "print('Test Accuracy of SVC',round(svc.score(X_test,y_test),5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My SVC predicts: [0. 1. 0. 0. 0. 1. 0. 1. 0. 1.]\n",
      "For those 10 Labels: [0. 1. 0. 0. 0. 1. 0. 1. 0. 1.]\n",
      "0.03124 Second to predict SVC..\n"
     ]
    }
   ],
   "source": [
    "# Check the prediction time for a single sample\n",
    "t=time.time()\n",
    "n_predict = 10\n",
    "print('My SVC predicts:', svc.predict(X_test[0:n_predict]))\n",
    "print('For those',n_predict,'Labels:',y_test[0:n_predict])\n",
    "print(round(time.time()-t,5),'Second to predict SVC..')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
